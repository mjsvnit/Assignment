{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203376ff",
   "metadata": {},
   "source": [
    "Ordinal Data: The categories have an inherent order\n",
    "Nominal Data: The categories do not have an inherent order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dfcf76",
   "metadata": {},
   "source": [
    "# Hash Encoder\n",
    "To understand Hash encoding it is necessary to know about hashing. Hashing is the transformation of arbitrary size input in the form of a fixed-size value. We use hashing algorithms to perform hashing operations i.e to generate the hash value of an input. Further, hashing is a one-way process, in other words, one can not generate original input from the hash representation.\n",
    "\n",
    "Hashing has several applications like data retrieval, checking data corruption, and in data encryption also. We have multiple hash functions available for example Message Digest (MD, MD2, MD5), Secure Hash Function (SHA0, SHA1, SHA2), and many more.\n",
    "\n",
    "Just like one-hot encoding, the Hash encoder represents categorical features using the new dimensions. Here, the user can fix the number of dimensions after transformation using n_component argument. Here is what I mean – A feature with 5 categories can be represented using N new features similarly, a feature with 100 categories can also be transformed using N new features. Doesn’t this sound amazing?\n",
    "\n",
    "By default, the Hashing encoder uses the md5 hashing algorithm but a user can pass any algorithm of his choice. If you want to explore the md5 algorithm, I suggest this paper.\n",
    "\n",
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "\n",
    "#Create the dataframe\n",
    "data=pd.DataFrame({'Month':['January','April','March','April','Februay','June','July','June','September']})\n",
    "\n",
    "#Create object for hash encoder\n",
    "encoder=ce.HashingEncoder(cols='Month',n_components=6)\n",
    "#Fit and Transform Data\n",
    "encoder.fit_transform(data)\n",
    "\n",
    "Since Hashing transforms the data in lesser dimensions, it may lead to loss of information. Another issue faced by hashing encoder is the collision. Since here, a large number of features are depicted into lesser dimensions, hence multiple values can be represented by the same hash value, this is known as a collision.\n",
    "\n",
    "Moreover, hashing encoders have been very successful in some Kaggle competitions. It is great to try if the dataset has high cardinality features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc63a6",
   "metadata": {},
   "source": [
    "# Q1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when youmight choose one over the other.\n",
    "\n",
    "Ordinal encoding and label encoding are both techniques used to transform categorical data into numerical data for use in machine learning models.\n",
    "\n",
    "Label encoding is a technique that assigns a unique integer value to each category in a categorical feature. For example, in a feature called \"color\" with categories \"red\", \"blue\", and \"green\", label encoding would assign \"red\" the value of 0, \"blue\" the value of 1, and \"green\" the value of 2. Label encoding does not take into account any inherent ordering or hierarchy among the categories.\n",
    "\n",
    "Ordinal encoding, on the other hand, takes into account any natural ordering or hierarchy among the categories in a categorical feature. It assigns an integer value to each category based on its rank or position within the ordered set of categories. For example, if a feature called \"education\" has categories \"high school\", \"college\", and \"graduate school\", ordinal encoding might assign \"high school\" the value of 1, \"college\" the value of 2, and \"graduate school\" the value of 3. This reflects the natural ordering of the categories based on level of education.\n",
    "\n",
    "In general, if there is no inherent ordering among the categories in a feature, label encoding is the more appropriate technique to use. If there is a natural ordering or hierarchy among the categories, then ordinal encoding should be used.\n",
    "\n",
    "For example, in a dataset containing a feature called \"rating\" with categories \"bad\", \"average\", \"good\", and \"excellent\", label encoding would be the appropriate choice since there is no inherent order to the categories. On the other hand, in a dataset containing a feature called \"income level\" with categories \"low\", \"medium\", and \"high\", ordinal encoding would be the more appropriate choice since there is a natural ordering among the categories based on income level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f258552",
   "metadata": {},
   "source": [
    "# Q2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in a machine learning project.\n",
    "Target Guided Ordinal Encoding is a technique of encoding categorical variables in such a way that it takes into account the target variable while encoding. In this technique, we replace each category of the categorical variable with a number. The number is determined based on the correlation between the category and the target variable.\n",
    "\n",
    "The following steps are involved in Target Guided Ordinal Encoding:\n",
    "\n",
    "1. Calculate the mean of the target variable for each category of the categorical variable.\n",
    "2. Order the categories based on their mean values.\n",
    "3. Replace each category with its corresponding rank.\n",
    "\n",
    "Let's consider an example where we have a dataset of customers in a bank. One of the columns in the dataset is the \"occupation\" of the customer, and the target variable is whether the customer has defaulted on a loan. We want to encode the \"occupation\" column to include it in a machine learning model. In this scenario, we can use Target Guided Ordinal Encoding to encode the \"occupation\" column by following these steps:\n",
    "\n",
    "Calculate the mean of the target variable (defaulted on loan) for each occupation category (e.g., engineer, doctor, teacher, etc.). Order the occupation categories based on their mean values (e.g., doctor, engineer, teacher, etc.). Replace each occupation category with its corresponding rank (e.g., doctor - 1, engineer - 2, teacher - 3, etc.). By using Target Guided Ordinal Encoding, we can transform the categorical variable \"occupation\" into a numerical variable that can be used in a machine learning model. This technique takes into account the relationship between the target variable and the categorical variable, making it a powerful tool for feature engineering in a machine learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d84fcba",
   "metadata": {},
   "source": [
    "# Q3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated?\n",
    "Covariance is a measure of the joint variability of two random variables. It describes the degree to which two variables are linearly associated with each other. A positive covariance indicates that when one variable increases, the other variable also tends to increase, while a negative covariance indicates that when one variable increases, the other variable tends to decrease.\n",
    "\n",
    "Covariance is important in statistical analysis because it helps to understand the relationship between two variables. It is often used to identify patterns in data and to identify variables that are related to each other. Covariance can also be used to calculate other important statistical measures, such as correlation and regression coefficients.\n",
    "\n",
    "\n",
    "The sample covariance is often used instead of the population covariance, which is calculated using the formula:\n",
    "\n",
    "cov(X,Y) = 1/(n-1) * sum((xi - mean(X))*(yi - mean(Y)))\n",
    "\n",
    "where n is the sample size, xi and yi are the individual observations of X and Y, and mean(X) and mean(Y) are the sample means.\n",
    "\n",
    "The sign of the covariance indicates the direction of the relationship between the two variables. A positive covariance indicates a positive relationship, while a negative covariance indicates a negative relationship. However, the magnitude of the covariance does not indicate the strength of the relationship, as it is influenced by the scale of the variables. Therefore, it is often more useful to use correlation coefficients, which standardize the covariance and provide a measure of the strength and direction of the linear relationship between two variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9c42de",
   "metadata": {},
   "source": [
    "# Q4 For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium, large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library. Show your code and explain the output.# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1042eb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color  Size  Material\n",
      "0      2     1         0\n",
      "1      1     2         1\n",
      "2      0     0         2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame([['red', 'medium', 'metal'], ['green', 'small', 'plastic'], ['blue', 'large', 'wood']], columns=['Color', 'Size', 'Material'])\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "data['Color'] = le.fit_transform(data['Color'])\n",
    "data['Size'] = le.fit_transform(data['Size'])\n",
    "data['Material'] = le.fit_transform(data['Material'])\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731ffea",
   "metadata": {},
   "source": [
    "# Q5 Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education level. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f5f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:\n",
      " [[1.22916667e+02 1.41666667e+05 3.58333333e+01]\n",
      " [1.41666667e+05 1.66666667e+08 4.33333333e+04]\n",
      " [3.58333333e+01 4.33333333e+04 1.16666667e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Assuming the dataset is stored in a NumPy array with columns Age, Income, and Education\n",
    "dataset = pd.DataFrame([[25, 50000, 12], [30, 60000, 16], [40, 70000, 18], [50, 80000, 20]],columns=[ 'Age', 'Income','Education'])\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "covariance_matrix = np.cov(dataset, rowvar=False)\n",
    "\n",
    "# Print the covariance matrix\n",
    "print(\"Covariance matrix:\\n\", covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae253575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>122.916667</td>\n",
       "      <td>1.416667e+05</td>\n",
       "      <td>35.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>141666.666667</td>\n",
       "      <td>1.666667e+08</td>\n",
       "      <td>43333.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>35.833333</td>\n",
       "      <td>4.333333e+04</td>\n",
       "      <td>11.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Age        Income     Education\n",
       "Age           122.916667  1.416667e+05     35.833333\n",
       "Income     141666.666667  1.666667e+08  43333.333333\n",
       "Education      35.833333  4.333333e+04     11.666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ba49d",
   "metadata": {},
   "source": [
    "# Q6 You are working on a machine learning project with a dataset containing several categorical variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD), and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for\n",
    "\n",
    "For the given categorical variables, I would use the following encoding methods:\n",
    "\n",
    "Gender: Binary encoding or label encoding can be used as there are only two unique categories. Binary encoding can be preferred as it reduces the number of features and is less prone to overfitting.\n",
    "\n",
    "Education Level: Ordinal encoding can be used as there is a clear order to the categories from low to high level of education. Target guided ordinal encoding can also be used if there is a correlation between the education level and the target variable.\n",
    "\n",
    "Employment Status: One-hot encoding can be used as there are more than two unique categories, and they do not have a clear order or ranking. Since there are only three categories, using one-hot encoding will not lead to a high number of features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754d0c9",
   "metadata": {},
   "source": [
    "# Q7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two categorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/ East/West). Calculate the covariance between each pair of variables and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7664217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.70e+00 -1.25e+01  3.00e-01 -4.50e-01  1.50e-01  3.00e-01 -9.00e-01\n",
      "   1.05e+00 -4.50e-01]\n",
      " [-1.25e+01  6.25e+01  0.00e+00  1.25e+00 -1.25e+00  0.00e+00  0.00e+00\n",
      "  -1.25e+00  1.25e+00]\n",
      " [ 3.00e-01  0.00e+00  2.00e-01 -5.00e-02 -1.50e-01  2.00e-01 -1.00e-01\n",
      "  -5.00e-02 -5.00e-02]\n",
      " [-4.50e-01  1.25e+00 -5.00e-02  2.00e-01 -1.50e-01 -5.00e-02 -1.00e-01\n",
      "  -5.00e-02  2.00e-01]\n",
      " [ 1.50e-01 -1.25e+00 -1.50e-01 -1.50e-01  3.00e-01 -1.50e-01  2.00e-01\n",
      "   1.00e-01 -1.50e-01]\n",
      " [ 3.00e-01  0.00e+00  2.00e-01 -5.00e-02 -1.50e-01  2.00e-01 -1.00e-01\n",
      "  -5.00e-02 -5.00e-02]\n",
      " [-9.00e-01  0.00e+00 -1.00e-01 -1.00e-01  2.00e-01 -1.00e-01  3.00e-01\n",
      "  -1.00e-01 -1.00e-01]\n",
      " [ 1.05e+00 -1.25e+00 -5.00e-02 -5.00e-02  1.00e-01 -5.00e-02 -1.00e-01\n",
      "   2.00e-01 -5.00e-02]\n",
      " [-4.50e-01  1.25e+00 -5.00e-02  2.00e-01 -1.50e-01 -5.00e-02 -1.00e-01\n",
      "  -5.00e-02  2.00e-01]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create example dataframe\n",
    "df = pd.DataFrame({\n",
    "    'Temperature': [20, 25, 22, 19, 18],\n",
    "    'Humidity': [40, 45, 50, 55, 60],\n",
    "    'Weather Condition': ['Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Sunny'],\n",
    "    'Wind Direction': ['North', 'South', 'East', 'West', 'North']\n",
    "})\n",
    "\n",
    "# encode categorical variables using one-hot encoding\n",
    "encoded_df = pd.get_dummies(df, columns=['Weather Condition', 'Wind Direction'])\n",
    "encoded_df= pd.DataFrame(encoded_df)\n",
    "# calculate covariance matrix\n",
    "cov_matrix = np.cov(encoded_df,\n",
    "                    rowvar=False)\n",
    "\n",
    "# print covariance matrix\n",
    "print(cov_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cbe2b9",
   "metadata": {},
   "source": [
    "The covariance matrix shows the covariance between each pair of variables. For example, the first row and first column shows the covariance between \"Temperature\" and \"Temperature\", which is 7.7. The second row and second column shows the covariance between \"Humidity\" and \"Humidity\", which is 62.5. The first row and second column shows the covariance between \"Temperature\" and \"Humidity\", which is -12.5. The matrix is symmetric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
