{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8489301",
   "metadata": {},
   "source": [
    "- The goal of linear SVM classification is to find the hyperplane that maximizes the margin between two classes. The margin is the distance between the hyperplane and the closest data points from each class. The larger the margin, the better the separation between the classes.\n",
    "- Kernel is a parameter of SVM classification, but it is not specific to linear SVM classification. It is used in non-linear SVM classification to transform the input data into a higher-dimensional space where a hyperplane can be used to separate the classes. C is the penalty parameter of the error term, gamma is a parameter of the RBF kernel, and tol is the tolerance for stopping criterion.\n",
    "- The kernel trick is used to transform the data into a higher-dimensional space where it is easier to separate the classes using a hyperplane. This is done by computing the dot product between the transformed data points, which is equivalent to applying a nonlinear function to the data.\n",
    "- The margin is the distance between the decision boundary and the closest data point from each class. In linear SVM, the goal is to find the decision boundary that maximizes the margin, as this results in better generalization performance.\n",
    "- The main difference between hard margin and soft margin SVM is that hard margin SVM does not allow for any misclassification, while soft margin SVM allows for some misclassification of the data points. This is done to increase the generalization performance of the model, especially when the data is not perfectly separable.\n",
    "- Cross-validation is a technique to prevent data leakage in SVM and other machine learning models. It involves splitting the data into training and validation sets multiple times and using the validation set to evaluate the performance of the model. This helps to ensure that the model does not overfit the training data and can generalize well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf75fed",
   "metadata": {},
   "source": [
    "## 6th April Assignment-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7250236a",
   "metadata": {},
   "source": [
    "## Q1. What is the mathematical formula for a linear SVM?                                               ##Q2. What is the objective function of a linear SVM?\n",
    "\n",
    "Ans 1 The mathematical formula for a linear SVM (Support Vector Machine) is given by:\n",
    "\n",
    "f(x) = sign(w^T x + b)\n",
    "\n",
    "where x is the input vector, w is the weight vector, b is the bias term, and sign() is the sign function which outputs +1 if the argument is positive and -1 if the argument is negative.\n",
    "\n",
    "**Ans 2**  The objective function of a linear SVM is to find the hyperplane that maximizes the margin between the two classes. The margin is defined as the distance between the hyperplane and the closest points of each class, also known as the support vectors. The objective function can be written as:\n",
    "\n",
    "minimize 1/2 ||w||^2\n",
    "\n",
    "subject to y_i(w^T x_i + b) â‰¥ 1 for all i = 1, ..., n\n",
    "\n",
    "where ||w|| is the Euclidean norm of the weight vector, y_i is the label of the i-th training sample, x_i is the i-th training sample, and b is the bias term. The constraint ensures that all training samples are correctly classified with a margin of at least 1. The objective function aims to find the weight vector w that minimizes the norm of w while satisfying the classification constraints. The solution to this optimization problem is the hyperplane that maximizes the margin between the two classes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "568c769e",
   "metadata": {},
   "source": [
    "## Q3. What is the kernel trick in SVM                                                                                   ##Q4. What is the role of support vectors in SVM Explain with example\n",
    "\n",
    "**Ans 3**. The kernel trick is a technique used in SVM to transform a nonlinearly separable problem into a linearly separable problem in a higher-dimensional space. It works by computing the dot product of the data points in the higher-dimensional space without actually computing their coordinates. This avoids the computational burden of explicitly mapping the data to the higher-dimensional space.\n",
    "\n",
    "**Ans 4** Support vectors play a crucial role in SVM. They are the data points closest to the decision boundary, or hyperplane, that separates the classes. These data points have the maximum margin, which is the distance between the hyperplane and the closest data points of each class.\n",
    "\n",
    "The support vectors are used to define the decision boundary and are the only points that are used to make predictions. This is because they represent the most informative points in the data that determine the position of the decision boundary.\n",
    "\n",
    "For example, suppose we have a dataset with two classes, represented by blue and red points in a two-dimensional space. The goal is to find a linear decision boundary that separates the classes. The black line in the figure below represents the decision boundary found by the SVM algorithm.\n",
    "\n",
    "\n",
    "The circled points are the support vectors, and they lie closest to the decision boundary. These points are used to define the hyperplane and make predictions. Any points that lie outside the margin but on the correct side of the decision boundary do not affect the position of the decision boundary and are called slack variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8024c24",
   "metadata": {},
   "source": [
    "## Q5. Illustrate with examples and graphs of Hyperplane, Marginal plane, Soft margin and Hard margin in SVM?\n",
    "\n",
    "Sure, I can illustrate these concepts with examples and graphs in SVM.\n",
    "\n",
    "1. **Hyperplane**:\n",
    "A hyperplane is a decision boundary that separates two classes in SVM. It is represented as a straight line in two dimensions and a hyperplane in higher dimensions. The goal of SVM is to find the hyperplane that maximizes the margin between the two classes. The margin is the distance between the hyperplane and the closest data points from each class.\n",
    "Example: In the below graph, the red and blue points represent two classes, and the black line is the hyperplane that separates them.\n",
    "\n",
    " \n",
    "\n",
    "2. **Marginal plane**:\n",
    "The marginal plane is the hyperplane that lies parallel to the optimal hyperplane and closest to the support vectors. It separates the support vectors from the rest of the data points and can be used to determine the margin of the SVM classifier.\n",
    "Example: In the below graph, the dashed lines represent the marginal planes, and the solid black line is the optimal hyperplane.\n",
    "\n",
    "3. **Soft margin**:\n",
    "The soft margin is a flexible margin that allows some data points to be misclassified to achieve a better overall margin. The objective of soft margin SVM is to find the optimal hyperplane that minimizes the sum of the margin and the penalty of misclassifications.\n",
    "Example: In the below graph, the red circle represents a misclassified point that is allowed by the soft margin.\n",
    "\n",
    "\n",
    "\n",
    "4. **Hard margin**:\n",
    "The hard margin is a strict margin that does not allow any misclassified data points. It works well when the data is linearly separable, but it may not be possible to find a hard margin in some cases.\n",
    "Example: In the below graph, the hard margin SVM cannot find a hyperplane that separates the two classes without any misclassification.\n",
    "\n",
    "\n",
    "In conclusion, SVM is a powerful algorithm that uses a hyperplane to separate two classes in a high-dimensional space. The margin of the SVM classifier is the distance between the hyperplane and the closest data points from each class. The marginal plane is the hyperplane that lies parallel to the optimal hyperplane and closest to the support vectors. Soft margin allows some misclassifications to achieve a better margin, while hard margin does not allow any misclassified data points.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307e034",
   "metadata": {},
   "source": [
    "## Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44288a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3e92b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "339b6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear SVM classifier\n",
    "svm_clf = SVC(kernel='linear', C=1)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing set\n",
    "y_pred = svm_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e223784b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b9f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy of the model on the testing set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d716753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mesh grid of the two features\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e499c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the decision boundaries of the trained model\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "h = 0.02\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = svm_clf.predict(np.c_[xx.ravel(), yy.ravel(), np.zeros_like(xx.ravel()), np.zeros_like(xx.ravel())])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('SVM Decision Boundary')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1975546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.1 Accuracy: 1.0\n",
      "C = 1 Accuracy: 1.0\n",
      "C = 10 Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "for C in [0.1, 1, 10]:\n",
    "    svm_clf = SVC(kernel='linear', C=C)\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    y_pred = svm_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('C =', C, 'Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f172b84",
   "metadata": {},
   "source": [
    "## 7th April Assignment-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2726ad",
   "metadata": {},
   "source": [
    "## Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
    "In machine learning, kernel functions are used to transform the input data into a higher-dimensional space to make it easier to separate into classes. Polynomial functions are one type of kernel function that is commonly used. Specifically, a polynomial kernel function calculates the dot product of two vectors in a higher-dimensional space defined by a polynomial function.\n",
    "\n",
    "Therefore, the relationship between polynomial functions and kernel functions in machine learning algorithms is that polynomial functions are used as kernel functions to transform the data into a higher-dimensional space. The degree of the polynomial kernel function determines the degree of the polynomial function used for the transformation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8116802d",
   "metadata": {},
   "source": [
    "## Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "\n",
    "To implement an SVM with a polynomial kernel in Python using Scikit-learn, we can use the SVC (Support Vector Classifier) class. Here is an example code that demonstrates how to use SVC with a polynomial kernel:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd2f569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7111111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # Take the first two features\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Create an SVM classifier with a polynomial kernel\n",
    "svm_poly = SVC(kernel='poly', degree=3)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = svm_poly.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = svm_poly.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923d5e4",
   "metadata": {},
   "source": [
    "## Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "In Support Vector Regression (SVR), epsilon is a hyperparameter that controls the width of the margin around the predicted values. It determines the maximum distance between the predicted values and the actual values that the model can tolerate.\n",
    "\n",
    "When the value of epsilon is increased, the number of support vectors in SVR typically increases. This is because a larger value of epsilon allows more data points to be included within the margin, which in turn requires more support vectors to define the boundary of the margin.\n",
    "\n",
    "However, it's worth noting that the relationship between epsilon and the number of support vectors is not always straightforward and can depend on the specific dataset and model parameters. In general, it's important to select an appropriate value of epsilon through cross-validation to balance the trade-off between model complexity (i.e., number of support vectors) and generalization performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1086bb",
   "metadata": {},
   "source": [
    "## Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "The performance of Support Vector Regression (SVR) can be affected by several parameters, including the choice of kernel function, C parameter, epsilon parameter, and gamma parameter. Here is an explanation of how each parameter works and how it affects the performance of SVR:\n",
    "\n",
    "- **Kernel function**: The kernel function determines the mapping of input features to higher dimensional space, where the linear regression model can be applied. Common kernel functions are linear, polynomial, radial basis function (RBF), and sigmoid. The choice of kernel function can affect the accuracy and speed of the SVR model. For example, if the data has non-linear patterns, then the RBF kernel may be more appropriate than a linear kernel.\n",
    "\n",
    "- **C parameter**: The C parameter controls the trade-off between maximizing the margin and minimizing the error. A smaller C value allows for a wider margin, while a larger C value results in a narrower margin but fewer errors. In general, a larger C value can result in better accuracy but may lead to overfitting.\n",
    "\n",
    "- **Epsilon parameter**: The epsilon parameter controls the width of the epsilon-insensitive band around the regression line. A larger epsilon value allows for more errors within the band, while a smaller epsilon value results in fewer errors within the band. In general, a larger epsilon value can lead to a smoother regression line, while a smaller epsilon value can result in a more accurate but potentially noisier regression line.\n",
    "\n",
    "- **Gamma parameter**: The gamma parameter controls the width of the kernel function. A larger gamma value results in a more complex decision boundary, while a smaller gamma value results in a smoother decision boundary. In general, a smaller gamma value can be useful for datasets with a large number of features, while a larger gamma value may be more appropriate for datasets with fewer features.\n",
    "\n",
    "Here are some examples of when you might want to increase or decrease each parameter:\n",
    "\n",
    "- **Kernel function**: If the data has linear patterns, then a linear kernel may be appropriate. However, if the data has non-linear patterns, then a non-linear kernel such as RBF or polynomial may be more appropriate.\n",
    "\n",
    "- **C parameter**: If you have a large amount of noise in your data, then you may want to increase the C value to reduce the margin and allow for more errors. However, if you have a small amount of noise, then you may want to decrease the C value to allow for a wider margin.\n",
    "\n",
    "- **Epsilon parameter**: If you have a large amount of noise in your data, then you may want to increase the epsilon value to allow for more errors within the band. However, if you have a small amount of noise, then you may want to decrease the epsilon value to minimize the number of errors within the band.\n",
    "\n",
    "- **Gamma parameter**: If you have a large number of features in your data, then you may want to decrease the gamma value to create a smoother decision boundary. However, if you have a small number of features, then you may want to increase the gamma value to create a more complex decision boundary that captures the relationships between the features.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0c36c",
   "metadata": {},
   "source": [
    "## Q5. Assignment:\n",
    "- Import the necessary libraries and load the dataseg\n",
    "- Split the dataset into training and testing setZ\n",
    "- Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "- Create an instance of the SVC classifier and train it on the training datW\n",
    "- hse the trained classifier to predict the labels of the testing datW\n",
    "- Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "- Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "- Train the tuned classifier on the entire dataseg\n",
    "- Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed7a363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.708 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.708 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.958 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=auto, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=auto, kernel=poly;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=auto, kernel=poly;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=auto, kernel=poly;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=auto, kernel=poly;, score=0.958 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=auto, kernel=poly;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=auto, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=auto, kernel=poly;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=auto, kernel=poly;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=auto, kernel=poly;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=auto, kernel=poly;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=auto, kernel=poly;, score=0.917 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svc_tuned.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess data using standard scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier and train it on the training data\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Tune hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "svc_tuned = grid.best_estimator_\n",
    "svc_tuned.fit(X, y)\n",
    "\n",
    "# Save the trained classifier to a file for future use\n",
    "joblib.dump(svc_tuned, 'svc_tuned.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148f69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1658f563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e9ec650",
   "metadata": {},
   "source": [
    "## Q2. You have built an SVM regression model and are trying to decide between using MSE or R-squared as your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price of a house as accurately as possible?\n",
    "\n",
    "In this scenario, if the goal is to predict the actual price of a house as accurately as possible, the most appropriate evaluation metric would be Mean Squared Error (MSE).\n",
    "\n",
    "MSE measures the average squared difference between the predicted and actual values, giving more weight to large errors. It provides a more detailed picture of the magnitude of the errors in the predictions and how they vary across the data.\n",
    "\n",
    "On the other hand, R-squared measures the proportion of the variance in the dependent variable that is explained by the independent variables, which is more appropriate for evaluating the goodness-of-fit of the model rather than the accuracy of predictions.\n",
    "\n",
    "Therefore, MSE would be a more suitable evaluation metric when the goal is to minimize prediction errors and obtain accurate predictions of the actual price of a house.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7394af",
   "metadata": {},
   "source": [
    "## Q3. You have a dataset with a significant number of outliers and are trying to select an appropriate regression metric to use with your SVM model. Which metric would be the most appropriate in this scenario?\n",
    "When dealing with a significant number of outliers in a dataset, mean squared error (MSE) may not be the most appropriate regression metric to use with an SVM model. This is because MSE is sensitive to outliers, meaning that a single outlier can significantly increase the error.\n",
    "\n",
    "In this scenario, a more robust regression metric such as mean absolute error (MAE) or median absolute error (MedAE) may be more appropriate. These metrics are less sensitive to outliers and give a more accurate representation of the model's performance on the majority of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c23d2e",
   "metadata": {},
   "source": [
    "## Q4. You have built an SVM regression model using a polynomial kernel and are trying to select the best metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values are very close. Which metric should you choose to use in this case?\n",
    "If both MSE and RMSE are very close, either metric could be used to evaluate the performance of the SVM regression model. However, RMSE is often preferred over MSE because it has the same units as the dependent variable, which can make it easier to interpret the magnitude of the errors in the predictions. Additionally, RMSE is less sensitive to large errors than MSE because of the square root operation, which can be useful if there are outliers in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e78aa2",
   "metadata": {},
   "source": [
    "## Q5. You are comparing the performance of different SVM regression models using different kernels (linear, polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most appropriate if your goal is to measure how well the model explains the variance in the target variable?\n",
    "\n",
    "The most appropriate metric to measure how well an SVM regression model explains the variance in the target variable is the coefficient of determination, also known as R-squared. R-squared measures the proportion of the variance in the dependent variable that is explained by the independent variables in the model. A higher R-squared indicates a better fit of the model to the data, which means that the model can better explain the variability of the target variable. Therefore, R-squared is a suitable metric for comparing the performance of SVM regression models with different kernels when the goal is to measure how well the model explains the variance in the target variable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
